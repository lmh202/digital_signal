"""
å­¤ç«‹å°–å³°æŒç»­æ—¶é—´åˆ†æè„šæœ¬ï¼ˆåŸå§‹ä¿¡å·ç‰ˆæœ¬ - æ— é¢„å¤„ç†ï¼‰
åŠŸèƒ½ï¼šç›´æ¥åœ¨åŸå§‹ä¿¡å·ä¸Šæ£€æµ‹å¼‚å¸¸å¤§çš„å³°å€¼ï¼Œç»Ÿè®¡è¿ç»­å¤§çš„ç¦»æ•£ç‚¹ä¸ªæ•°ï¼Œè®¡ç®—æŒç»­æ—¶é—´
"""

import numpy as np
import matplotlib.pyplot as plt
from scipy.signal import find_peaks
import os
import glob
import json

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# ==================== å‚æ•°è®¾ç½® ====================
SAMPLE_RATE = 51200  # é‡‡æ ·ç‡ Hz
DATA_DIR = "."  # æ•°æ®ç›®å½•
OUTPUT_DIR = "peak_duration_analysis_raw"  # è¾“å‡ºç›®å½•

# å³°å€¼æ£€æµ‹å‚æ•°ï¼ˆç›´æ¥åœ¨åŸå§‹ä¿¡å·ä¸Šï¼‰
PEAK_THRESHOLD_RATIO = 0.3  # å³°å€¼é˜ˆå€¼ï¼šä¿¡å·ç»å¯¹å€¼çš„ç™¾åˆ†ä½æ•°ï¼ˆå¦‚0.3è¡¨ç¤ºå–å‰30%çš„å¤§å€¼ï¼‰
PEAK_MIN_DISTANCE = 256  # ç›¸é‚»å³°å€¼æœ€å°é—´éš”ï¼ˆé‡‡æ ·ç‚¹æ•°ï¼‰

# æŒç»­æ—¶é—´è®¡ç®—å‚æ•°
DURATION_THRESHOLD_RATIO = 0.3  # æŒç»­æ—¶é—´è¾¹ç•Œé˜ˆå€¼ï¼ˆç›¸å¯¹äºå³°å€¼çš„æ¯”ä¾‹ï¼‰


def create_output_dir():
    """åˆ›å»ºè¾“å‡ºç›®å½•"""
    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)
        print(f"å·²åˆ›å»ºè¾“å‡ºç›®å½•: {OUTPUT_DIR}")


def load_data(filepath):
    """åŠ è½½æ•°æ®æ–‡ä»¶"""
    data = np.loadtxt(filepath)
    return data


def compute_envelope(signal_data, sample_rate=SAMPLE_RATE, 
                     low_freq=BANDPASS_LOW, high_freq=BANDPASS_HIGH):
    """
    è®¡ç®—ä¿¡å·åŒ…ç»œ
    æ­¥éª¤ï¼š
    1. å¸¦é€šæ»¤æ³¢ï¼ˆå»é™¤ç›´æµå’Œé«˜é¢‘å™ªå£°ï¼‰
    2. æ•´æµï¼ˆå–ç»å¯¹å€¼ï¼‰
    3. ä½é€šæ»¤æ³¢å¹³æ»‘ï¼ˆç§»åŠ¨å¹³å‡ï¼‰
    """
    # å¸¦é€šæ»¤æ³¢
    nyquist = sample_rate / 2
    low = low_freq / nyquist
    high = high_freq / nyquist
    b, a = signal.butter(4, [low, high], btype='band')
    filtered_signal = signal.filtfilt(b, a, signal_data)
    
    # æ•´æµ
    rectified = np.abs(filtered_signal)
    
    # ç§»åŠ¨å¹³å‡å¹³æ»‘
    window_size = 512
    window = np.ones(window_size) / window_size
    envelope = np.convolve(rectified, window, mode='same')
    
    return envelope


def analyze_peak_duration(signal_data, sample_rate=SAMPLE_RATE):
    """
    åˆ†ææ¯ä¸ªå­¤ç«‹å³°çš„æŒç»­æ—¶é—´
    
    è¿”å›ï¼š
        peak_info: åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯å­—å…¸ {
            'peak_idx': å³°å€¼ä½ç½®ç´¢å¼•,
            'peak_amplitude': å³°å€¼å¹…å€¼,
            'start_idx': èµ·å§‹ä½ç½®,
            'end_idx': ç»“æŸä½ç½®,
            'duration_samples': æŒç»­é‡‡æ ·ç‚¹æ•°,
            'duration_ms': æŒç»­æ—¶é—´(æ¯«ç§’)
        }
    """
    # è®¡ç®—åŒ…ç»œ
    envelope = compute_envelope(signal_data, sample_rate=sample_rate)
    
    # æ£€æµ‹å³°å€¼
    min_distance_samples = int(PEAK_MIN_DISTANCE * sample_rate)
    peaks, properties = find_peaks(
        envelope,
        height=MIN_PEAK_AMPLITUDE,
        distance=min_distance_samples
    )
    
    if len(peaks) == 0:
        return []
    
    peak_info = []
    
    # å¯¹æ¯ä¸ªå³°å€¼è®¡ç®—æŒç»­æ—¶é—´
    for i, peak_idx in enumerate(peaks):
        peak_value = envelope[peak_idx]
        threshold = peak_value * DURATION_THRESHOLD_RATIO
        
        # === å‘å‰æœç´¢èµ·ç‚¹ ===
        start_idx = peak_idx
        for idx in range(peak_idx - 1, -1, -1):
            if envelope[idx] >= threshold:
                start_idx = idx
            else:
                break
        
        # === å‘åæœç´¢ç»ˆç‚¹ ===
        end_idx = peak_idx
        for idx in range(peak_idx + 1, len(envelope)):
            if envelope[idx] >= threshold:
                end_idx = idx
            else:
                break
        
        # è®¡ç®—æŒç»­æ—¶é—´
        duration_samples = end_idx - start_idx + 1
        duration_ms = duration_samples / sample_rate * 1000
        
        peak_info.append({
            'peak_idx': int(peak_idx),
            'peak_amplitude': float(peak_value),
            'start_idx': int(start_idx),
            'end_idx': int(end_idx),
            'duration_samples': int(duration_samples),
            'duration_ms': float(duration_ms)
        })
    
    return peak_info


def plot_peak_duration_distribution(all_results):
    """ç»˜åˆ¶æ‰€æœ‰æ–‡ä»¶çš„å³°å€¼æŒç»­æ—¶é—´åˆ†å¸ƒå›¾"""
    fig, axes = plt.subplots(2, 1, figsize=(14, 10))
    
    # å‡†å¤‡æ•°æ®
    tightness_values = sorted(all_results.keys())
    
    # === å­å›¾1: æŒç»­æ—¶é—´ç®±çº¿å›¾ ===
    durations_by_file = []
    labels = []
    for tight in tightness_values:
        durations = [p['duration_ms'] for p in all_results[tight]['peaks']]
        durations_by_file.append(durations)
        labels.append(f"{tight}")
    
    bp = axes[0].boxplot(durations_by_file, labels=labels, patch_artist=True)
    
    # è®¾ç½®é¢œè‰²
    for patch in bp['boxes']:
        patch.set_facecolor('lightblue')
    
    axes[0].axhline(y=10, color='orange', linestyle='--', linewidth=1.5, label='10ms (æ¯›åˆºé˜ˆå€¼)')
    axes[0].axhline(y=20, color='green', linestyle='--', linewidth=1.5, label='20ms (çœŸå®æ•²å‡»é˜ˆå€¼)')
    axes[0].set_xlabel('æ¾ç´§åº¦')
    axes[0].set_ylabel('æŒç»­æ—¶é—´ (ms)')
    axes[0].set_title('å„æ–‡ä»¶å³°å€¼æŒç»­æ—¶é—´åˆ†å¸ƒï¼ˆç®±çº¿å›¾ï¼‰')
    axes[0].grid(True, alpha=0.3, axis='y')
    axes[0].legend()
    
    # === å­å›¾2: æŒç»­æ—¶é—´ç»Ÿè®¡æŸ±çŠ¶å›¾ ===
    categories = ['<10ms\n(æ¯›åˆº)', '10-20ms\n(ç°è‰²åœ°å¸¦)', 'â‰¥20ms\n(çœŸå®æ•²å‡»)']
    width = 0.15
    x = np.arange(len(tightness_values))
    
    short_counts = []
    medium_counts = []
    long_counts = []
    
    for tight in tightness_values:
        durations = [p['duration_ms'] for p in all_results[tight]['peaks']]
        short_counts.append(sum(1 for d in durations if d < 10))
        medium_counts.append(sum(1 for d in durations if 10 <= d < 20))
        long_counts.append(sum(1 for d in durations if d >= 20))
    
    axes[1].bar(x - width, short_counts, width, label='<10ms (æ¯›åˆº)', color='red', alpha=0.7)
    axes[1].bar(x, medium_counts, width, label='10-20ms (ç°è‰²åœ°å¸¦)', color='orange', alpha=0.7)
    axes[1].bar(x + width, long_counts, width, label='â‰¥20ms (çœŸå®æ•²å‡»)', color='green', alpha=0.7)
    
    axes[1].set_xlabel('æ¾ç´§åº¦')
    axes[1].set_ylabel('å³°å€¼æ•°é‡')
    axes[1].set_title('å„æ–‡ä»¶å³°å€¼æŒç»­æ—¶é—´åˆ†ç±»ç»Ÿè®¡')
    axes[1].set_xticks(x)
    axes[1].set_xticklabels(labels)
    axes[1].legend()
    axes[1].grid(True, alpha=0.3, axis='y')
    
    plt.tight_layout()
    save_path = os.path.join(OUTPUT_DIR, "peak_duration_distribution.png")
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close()
    print(f"\næŒç»­æ—¶é—´åˆ†å¸ƒå›¾å·²ä¿å­˜: {save_path}")


def plot_individual_file_histogram(tightness, peak_info, filename):
    """ç»˜åˆ¶å•ä¸ªæ–‡ä»¶çš„æŒç»­æ—¶é—´ç›´æ–¹å›¾"""
    durations = [p['duration_ms'] for p in peak_info]
    
    fig, ax = plt.subplots(figsize=(10, 6))
    
    # ç»˜åˆ¶ç›´æ–¹å›¾
    n, bins, patches = ax.hist(durations, bins=30, edgecolor='black', alpha=0.7)
    
    # æ ‡è®°é˜ˆå€¼çº¿
    ax.axvline(x=10, color='orange', linestyle='--', linewidth=2, label='10ms (æ¯›åˆºé˜ˆå€¼)')
    ax.axvline(x=20, color='green', linestyle='--', linewidth=2, label='20ms (çœŸå®æ•²å‡»é˜ˆå€¼)')
    
    ax.set_xlabel('æŒç»­æ—¶é—´ (ms)')
    ax.set_ylabel('å³°å€¼æ•°é‡')
    ax.set_title(f'æ¾ç´§åº¦ {tightness} - å³°å€¼æŒç»­æ—¶é—´åˆ†å¸ƒç›´æ–¹å›¾')
    ax.legend()
    ax.grid(True, alpha=0.3, axis='y')
    
    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯æ–‡æœ¬
    stats_text = f"æ€»å³°å€¼æ•°: {len(durations)}\n"
    stats_text += f"æœ€å°: {np.min(durations):.1f} ms\n"
    stats_text += f"æœ€å¤§: {np.max(durations):.1f} ms\n"
    stats_text += f"å¹³å‡: {np.mean(durations):.1f} ms\n"
    stats_text += f"ä¸­ä½æ•°: {np.median(durations):.1f} ms"
    ax.text(0.98, 0.97, stats_text, transform=ax.transAxes,
            verticalalignment='top', horizontalalignment='right',
            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5),
            fontsize=10)
    
    plt.tight_layout()
    save_path = os.path.join(OUTPUT_DIR, f"{filename}_duration_histogram.png")
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close()


def main():
    """ä¸»å‡½æ•°"""
    print("="*70)
    print("å­¤ç«‹å°–å³°æŒç»­æ—¶é—´åˆ†æ")
    print("="*70)
    print(f"é‡‡æ ·ç‡: {SAMPLE_RATE} Hz")
    print(f"æœ€å°å³°å€¼å¹…å€¼: {MIN_PEAK_AMPLITUDE}")
    print(f"æŒç»­æ—¶é—´é˜ˆå€¼æ¯”ä¾‹: {DURATION_THRESHOLD_RATIO} (ç›¸å¯¹äºå³°å€¼)")
    print("="*70)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    create_output_dir()
    
    # è·å–æ‰€æœ‰æ•°æ®æ–‡ä»¶
    data_files = sorted(glob.glob(os.path.join(DATA_DIR, "acquisitionData-*.txt")))
    print(f"\næ‰¾åˆ° {len(data_files)} ä¸ªæ•°æ®æ–‡ä»¶\n")
    
    if len(data_files) == 0:
        print("é”™è¯¯: æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶!")
        return
    
    # å¤„ç†æ‰€æœ‰æ–‡ä»¶
    all_results = {}
    
    for filepath in data_files:
        basename = os.path.basename(filepath)
        filename = os.path.splitext(basename)[0]
        tightness = int(filename.split('-')[1])
        
        print(f"{'='*70}")
        print(f"å¤„ç†æ–‡ä»¶: {basename} (æ¾ç´§åº¦: {tightness})")
        print(f"{'='*70}")
        
        # åŠ è½½æ•°æ®
        signal_data = load_data(filepath)
        print(f"æ•°æ®é•¿åº¦: {len(signal_data)} é‡‡æ ·ç‚¹, æ—¶é•¿: {len(signal_data)/SAMPLE_RATE:.2f} ç§’")
        
        # åˆ†æå³°å€¼æŒç»­æ—¶é—´
        peak_info = analyze_peak_duration(signal_data)
        
        if len(peak_info) == 0:
            print("âš ï¸  æœªæ£€æµ‹åˆ°å³°å€¼\n")
            continue
        
        # ç»Ÿè®¡ä¿¡æ¯
        durations_ms = [p['duration_ms'] for p in peak_info]
        durations_samples = [p['duration_samples'] for p in peak_info]
        
        print(f"\nğŸ“Š æ£€æµ‹åˆ° {len(peak_info)} ä¸ªå³°å€¼")
        print(f"\næŒç»­é‡‡æ ·ç‚¹æ•°ç»Ÿè®¡:")
        print(f"  æœ€å°: {np.min(durations_samples)} é‡‡æ ·ç‚¹")
        print(f"  æœ€å¤§: {np.max(durations_samples)} é‡‡æ ·ç‚¹")
        print(f"  å¹³å‡: {np.mean(durations_samples):.1f} é‡‡æ ·ç‚¹")
        print(f"  ä¸­ä½æ•°: {np.median(durations_samples):.1f} é‡‡æ ·ç‚¹")
        
        print(f"\næŒç»­æ—¶é—´ç»Ÿè®¡ (æ¯«ç§’):")
        print(f"  æœ€å°: {np.min(durations_ms):.2f} ms")
        print(f"  æœ€å¤§: {np.max(durations_ms):.2f} ms")
        print(f"  å¹³å‡: {np.mean(durations_ms):.2f} ms")
        print(f"  ä¸­ä½æ•°: {np.median(durations_ms):.2f} ms")
        
        # åˆ†ç±»ç»Ÿè®¡
        short_count = sum(1 for d in durations_ms if d < 10)
        medium_count = sum(1 for d in durations_ms if 10 <= d < 20)
        long_count = sum(1 for d in durations_ms if d >= 20)
        
        print(f"\næŒç»­æ—¶é—´åˆ†ç±»:")
        print(f"  < 10ms (ç–‘ä¼¼æ¯›åˆº):  {short_count} ä¸ª ({short_count/len(peak_info)*100:.1f}%)")
        print(f"  10-20ms (ç°è‰²åœ°å¸¦): {medium_count} ä¸ª ({medium_count/len(peak_info)*100:.1f}%)")
        print(f"  â‰¥ 20ms (çœŸå®æ•²å‡»):  {long_count} ä¸ª ({long_count/len(peak_info)*100:.1f}%)")
        
        # æ˜¾ç¤ºå‰10ä¸ªå³°å€¼çš„è¯¦ç»†ä¿¡æ¯
        print(f"\nå‰10ä¸ªå³°å€¼è¯¦ç»†ä¿¡æ¯:")
        print(f"{'åºå·':<6} {'å³°å€¼ä½ç½®':<12} {'å¹…å€¼':<10} {'èµ·å§‹':<10} {'ç»“æŸ':<10} {'é‡‡æ ·ç‚¹æ•°':<12} {'æŒç»­æ—¶é—´(ms)':<15}")
        print("-" * 85)
        for i, p in enumerate(peak_info[:10]):
            print(f"{i+1:<6} {p['peak_idx']:<12} {p['peak_amplitude']:<10.4f} "
                  f"{p['start_idx']:<10} {p['end_idx']:<10} {p['duration_samples']:<12} "
                  f"{p['duration_ms']:<15.2f}")
        
        if len(peak_info) > 10:
            print(f"... (è¿˜æœ‰ {len(peak_info)-10} ä¸ªå³°å€¼)")
        
        print()
        
        # ä¿å­˜ç»“æœ
        all_results[tightness] = {
            'filename': basename,
            'num_peaks': len(peak_info),
            'peaks': peak_info,
            'statistics': {
                'duration_samples_min': int(np.min(durations_samples)),
                'duration_samples_max': int(np.max(durations_samples)),
                'duration_samples_mean': float(np.mean(durations_samples)),
                'duration_samples_median': float(np.median(durations_samples)),
                'duration_ms_min': float(np.min(durations_ms)),
                'duration_ms_max': float(np.max(durations_ms)),
                'duration_ms_mean': float(np.mean(durations_ms)),
                'duration_ms_median': float(np.median(durations_ms)),
                'short_count': int(short_count),
                'medium_count': int(medium_count),
                'long_count': int(long_count)
            }
        }
        
        # ç»˜åˆ¶å•ä¸ªæ–‡ä»¶çš„ç›´æ–¹å›¾
        plot_individual_file_histogram(tightness, peak_info, filename)
    
    # ä¿å­˜æ‰€æœ‰ç»“æœåˆ°JSON
    json_path = os.path.join(OUTPUT_DIR, "peak_duration_results.json")
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(all_results, f, indent=2, ensure_ascii=False)
    print(f"\næ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: {json_path}")
    
    # ç»˜åˆ¶æ±‡æ€»å›¾
    if len(all_results) > 0:
        plot_peak_duration_distribution(all_results)
    
    # æ‰“å°æ±‡æ€»è¡¨æ ¼
    print("\n" + "="*70)
    print("æ±‡æ€»ç»Ÿè®¡è¡¨")
    print("="*70)
    print(f"{'æ¾ç´§åº¦':<10} {'å³°å€¼æ•°':<10} {'å¹³å‡æŒç»­(ms)':<15} {'<10ms':<10} {'10-20ms':<10} {'â‰¥20ms':<10}")
    print("-" * 70)
    
    for tight in sorted(all_results.keys()):
        stats = all_results[tight]['statistics']
        print(f"{tight:<10} {all_results[tight]['num_peaks']:<10} "
              f"{stats['duration_ms_mean']:<15.2f} "
              f"{stats['short_count']:<10} {stats['medium_count']:<10} {stats['long_count']:<10}")
    
    print("\n" + "="*70)
    print("åˆ†æå®Œæˆ!")
    print("="*70)
    print(f"ç»“æœå·²ä¿å­˜åˆ°ç›®å½•: {OUTPUT_DIR}/")
    print("  - peak_duration_results.json: è¯¦ç»†æ•°æ®")
    print("  - peak_duration_distribution.png: æ±‡æ€»åˆ†å¸ƒå›¾")
    print("  - *_duration_histogram.png: å„æ–‡ä»¶ç›´æ–¹å›¾")


if __name__ == "__main__":
    main()
